{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation\n",
    "> This module evaluating RL agents on the electricity market environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import itertools\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rliable.metrics\n",
    "import rliable.plot_utils\n",
    "import seaborn as sns\n",
    "\n",
    "from electricity_market.env import ElectricityMarketEnv\n",
    "from electricity_market.player import (\n",
    "    A2CAgent,\n",
    "    MaskablePPOAgent,\n",
    "    MaskableRandomAgent,\n",
    "    expert_knowledge_action_masks,\n",
    "    is_action_safe,\n",
    ")\n",
    "from electricity_market.utils import EvaluationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def plot_all_metrics(\n",
    "    agent_eval_data: dict[str, EvaluationData],\n",
    "):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    def plot_aggregate_metrics():\n",
    "        metrics = {\n",
    "            \"IQM\": [],\n",
    "            \"Median\": [],\n",
    "            \"Mean\": [],\n",
    "        }\n",
    "        agent_names = list(agent_eval_data.keys())\n",
    "\n",
    "        for agent, data in agent_eval_data.items():\n",
    "            rewards_matrix = np.array(data.rewards).reshape(len(data.rewards), 1)\n",
    "\n",
    "            metrics[\"IQM\"].append(rliable.metrics.aggregate_iqm(rewards_matrix))\n",
    "            metrics[\"Median\"].append(rliable.metrics.aggregate_median(rewards_matrix))\n",
    "            metrics[\"Mean\"].append(rliable.metrics.aggregate_mean(rewards_matrix))\n",
    "\n",
    "        # Create subplots for each metric\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        for ax, (metric_name, values) in zip(axes, metrics.items()):\n",
    "            sns.barplot(\n",
    "                x=agent_names,\n",
    "                y=values,\n",
    "                ax=ax,\n",
    "                hue=agent_names,\n",
    "                palette=\"tab10\",\n",
    "                capsize=0.1,\n",
    "                legend=False,\n",
    "            )\n",
    "            ax.set_title(f\"{metric_name} Reward\")\n",
    "            ax.set_xlabel(\"Agent\")\n",
    "            ax.set_ylabel(\"Reward\")\n",
    "            ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        plt.suptitle(\"Aggregate Evaluation Metrics (rliable)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_probability_of_improvement():\n",
    "        # Create a list of all agents (keys from agent_eval_data)\n",
    "        agents = list(agent_eval_data.keys())\n",
    "\n",
    "        # Dictionaries to hold the probability estimates and interval estimates\n",
    "        probability_estimates = {}\n",
    "        probability_interval_estimates = {}\n",
    "\n",
    "        # Compare each pair of agents using itertools.combinations\n",
    "        for agent1, agent2 in itertools.combinations(agents, 2):\n",
    "            # Get the rewards for each agent as lists\n",
    "            rewards1 = agent_eval_data[agent1].rewards\n",
    "            rewards2 = agent_eval_data[agent2].rewards\n",
    "\n",
    "            rewards1_reshaped = np.array(rewards1).reshape(len(rewards1), 1)\n",
    "            rewards2_reshaped = np.array(rewards2).reshape(len(rewards2), 1)\n",
    "\n",
    "            # Calculate the probability of improvement between the two agents\n",
    "            prob_improvement = rliable.metrics.probability_of_improvement(\n",
    "                rewards1_reshaped, rewards2_reshaped\n",
    "            )\n",
    "\n",
    "            # Calculate the confidence intervals (e.g., bootstrap method, here assuming it is available)\n",
    "            # If you have an existing method to calculate the intervals, apply it\n",
    "            # For simplicity, we use placeholders here\n",
    "            prob_interval = [0.0, 1.0]  # Replace with actual interval calculation\n",
    "\n",
    "            # Store the probability and interval estimates\n",
    "            pair = f\"{agent1},{agent2}\"\n",
    "            probability_estimates[pair] = prob_improvement\n",
    "            probability_interval_estimates[pair] = prob_interval\n",
    "\n",
    "        # Plot the probability of improvement using the rliable function\n",
    "        rliable.plot_utils.plot_probability_of_improvement(\n",
    "            probability_estimates,\n",
    "            probability_interval_estimates,\n",
    "            ax=None,\n",
    "            figsize=(8, 6),\n",
    "            colors=None,\n",
    "            color_palette=\"colorblind\",\n",
    "            alpha=0.75,\n",
    "            xlabel=\"P(X > Y)\",\n",
    "            left_ylabel=\"Algorithm X\",\n",
    "            right_ylabel=\"Algorithm Y\",\n",
    "        )\n",
    "\n",
    "        plt.title(\"Probability of Improvement between Algorithms\")\n",
    "        plt.show()\n",
    "\n",
    "    # Call all the plot functions\n",
    "    plot_aggregate_metrics()\n",
    "    plot_probability_of_improvement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "with open(\"evaluation_data_per_agent.pkl\", \"rb\") as f:\n",
    "    evaluation_data_per_agent = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "plot_all_metrics(evaluation_data_per_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "maskable_random_agent = MaskableRandomAgent()\n",
    "maskable_random_agent.evaluate(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "a2c_agent = A2CAgent()\n",
    "a2c_agent.load_model(Path(\"../trained_models/A2CAgent.model\"))\n",
    "a2c_agent.evaluate(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "maskable_ppo_agent = MaskablePPOAgent()\n",
    "maskable_ppo_agent.load_model(Path(\"../trained_models/MaskablePPOAgent.model\"))\n",
    "maskable_ppo_agent.evaluate(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "optimized_maskable_ppo_agent = MaskablePPOAgent()\n",
    "optimized_maskable_ppo_agent.load_model(\n",
    "    Path(\"../trained_models/OptimizedMaskablePPOAgent.model\")\n",
    ")\n",
    "optimized_maskable_ppo_agent.evaluate(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# Dynamically overriding action_masks to ElectricityMarketEnv\n",
    "setattr(ElectricityMarketEnv, \"action_masks\", expert_knowledge_action_masks)\n",
    "# Dynamically overriding injection is_action_safe to ElectricityMarketEnv\n",
    "setattr(ElectricityMarketEnv, \"is_action_safe\", is_action_safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "expert_maskable_random_agent = MaskableRandomAgent()\n",
    "expert_maskable_random_agent.evaluate(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "expert_maskable_ppo_agent = MaskablePPOAgent()\n",
    "expert_maskable_ppo_agent.load_model(\n",
    "    Path(\"../trained_models/ExpertMaskablePPOAgent.model\")\n",
    ")\n",
    "expert_maskable_ppo_agent.evaluate(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "optimized_expert_maskable_ppo_agent = MaskablePPOAgent()\n",
    "optimized_expert_maskable_ppo_agent.load_model(\n",
    "    Path(\"../trained_models/OptimizedExpertMaskablePPOAgent.model\")\n",
    ")\n",
    "optimized_expert_maskable_ppo_agent.evaluate(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
